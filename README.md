# Perturbed Report Discrimination for Biomedical Vision-Language Models

## Overview
The approach enhances vision-language models by introducing text perturbation techniques for improving semantic understanding in biomedical applications.
<img src="readme/Per_arch.png" alt="Per_arch" title="Per_arch" width="500"/>


## Installation
```bash
# Clone this repository
git clone https://github.com/ygritte723/perturbed_vlm.git
# Install dependencies
pip install -r requirements.txt
```

## Dataset
The model is trained on a curated dataset of biomedical images and associated reports. The dataset includes perturbed reports generated by specific text manipulation rules.
- Open-I: Chest X-ray dataset with radiology reports
- RadNLI and MedNLI: Benchmarks containing labelled hypothesis and premise pairs
- CheXpert: Chest radiographs with associated radiology reports

## Usage
Detailed instructions on how to use the model for training and inference.

## Methodology
### Approach
The model distinguishes between original biomedical reports and their perturbed versions, paired with images. 

#### Text Perturbation Methods
| Perturbation Type | Description |
| ----------------- | ----------- |
| Shuffle Words | Randomly shuffles words in a sentence |
| Reverse Sentence | Reverses the order of words in a sentence |
| ... | ... |

## Evaluation
- Fine-tuning on RadNLI and MedNLI for text classification
- Multi-task image classification on CheXpert
- Zero-shot clinical semantic structure evaluation on Open-I dataset
